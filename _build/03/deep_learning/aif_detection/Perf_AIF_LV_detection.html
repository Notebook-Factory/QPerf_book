---
redirect_from:
  - "/03/deep-learning/aif-detection/perf-aif-lv-detection"
interact_link: content/03/deep_learning/aif_detection/Perf_AIF_LV_detection.ipynb
kernel_name: python3
kernel_path: content/03/deep_learning/aif_detection
has_widgets: false
title: |-
  Perfusion AIF LV detection
pagenum: 2
prev_page:
  url: /01/abstract.html
next_page:
  url: /03/deep_learning/analysis/PerfusionSeg.html
suffix: .ipynb
search: data image mr model hui xue train automated detection lv arterial input function aif series cardiac perfusion deployment scanner author nih gov load check loaded properly construct loaders augmentation multi class trainer binary segmenation saving

comment: "***PROGRAMMATICALLY GENERATED, DO NOT EDIT. SEE ORIGINAL FILES IN /content***"
---

    <main class="jupyter-page">
    <div id="page-info"><div id="page-title">Perfusion AIF LV detection</div>
</div>
    <div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Automated-detection-of-LV-from-arterial-input-function-(AIF)-image-series-for-cardiac-MR-perfusion-with-model-deployment-to-MR-scanner">Automated detection of LV from arterial input function (AIF) image series for cardiac MR perfusion with model deployment to MR scanner<a class="anchor-link" href="#Automated-detection-of-LV-from-arterial-input-function-(AIF)-image-series-for-cardiac-MR-perfusion-with-model-deployment-to-MR-scanner"> </a></h1><p><strong>Author</strong>: <code>Hui Xue &lt;hui.xue@nih.gov&gt;</code></p>

</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1">#import os</span>
<span class="c1">#os.environ[&#39;CUDA_DEVICE_ORDER&#39;]=&#39;PCI_BUS_ID&#39;</span>
<span class="c1">#os.environ[&#39;CUDA_VISIBLE_DEVICES&#39;]=&#39;1,2&#39;</span>

<span class="kn">from</span> <span class="nn">IPython.core.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">HTML</span>
<span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="s2">&quot;&lt;style&gt;.container { width:90% !important; }&lt;/style&gt;&quot;</span><span class="p">))</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">sampler</span>
<span class="kn">import</span> <span class="nn">torch.onnx</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torchvision.datasets</span> <span class="k">as</span> <span class="nn">dset</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">T</span>
<span class="kn">from</span> <span class="nn">torchvision.utils</span> <span class="kn">import</span> <span class="o">*</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">collections</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">animation</span><span class="p">,</span> <span class="n">rc</span>
<span class="n">animation</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;animation.writer&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;ffmpeg&#39;</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">&#39;animation.ffmpeg_path&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;/usr/bin/ffmpeg&#39;</span>

<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">from</span> <span class="nn">scipy.spatial</span> <span class="kn">import</span> <span class="n">ConvexHull</span>
<span class="kn">from</span> <span class="nn">scipy.ndimage.morphology</span> <span class="kn">import</span> <span class="n">binary_fill_holes</span>

<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">OrderedDict</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">tensorboardX</span> <span class="kn">import</span> <span class="n">SummaryWriter</span>

<span class="kn">from</span> <span class="nn">skimage</span> <span class="kn">import</span> <span class="n">io</span><span class="p">,</span> <span class="n">transform</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">display</span><span class="p">,</span> <span class="n">clear_output</span><span class="p">,</span> <span class="n">HTML</span><span class="p">,</span> <span class="n">Image</span>

<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">import</span> <span class="nn">imp</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">shutil</span>
<span class="kn">import</span> <span class="nn">scipy.misc</span>
<span class="kn">from</span> <span class="nn">glob</span> <span class="kn">import</span> <span class="n">glob</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<style>.container { width:90% !important; }</style>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">training</span>
<span class="kn">import</span> <span class="nn">models</span>
<span class="kn">import</span> <span class="nn">utils</span>
<span class="kn">import</span> <span class="nn">utils.cmr_ml_utils_plotting</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">show</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
    <span class="n">npimg</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">npimg</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">npimg</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">)),</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Load-image-data">Load image data<a class="anchor-link" href="#Load-image-data"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">img_dir</span> <span class="o">=</span> <span class="s1">&#39;./data&#39;</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">scipy.io</span>

<span class="k">class</span> <span class="nc">PerfAIFDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Perfusion AIF dataset.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img_dir</span><span class="p">,</span> <span class="n">which_mask</span><span class="o">=</span><span class="s1">&#39;LV_RV&#39;</span><span class="p">,</span> <span class="n">min_reps</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            img_dir (string): Directory with all the images.</span>
<span class="sd">            transform (callable, optional): Optional transform to be applied on a sample.</span>
<span class="sd">            which_mask: LV or LV_RV</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span> <span class="o">=</span> <span class="n">img_dir</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">which_mask</span> <span class="o">=</span> <span class="n">which_mask</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">min_reps</span> <span class="o">=</span> <span class="n">min_reps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W</span> <span class="o">=</span> <span class="n">W</span>
        
        <span class="c1"># find all images</span>
        <span class="n">locations</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">loc</span> <span class="ow">in</span> <span class="n">locations</span><span class="p">:</span>
            <span class="k">if</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span><span class="p">,</span> <span class="n">loc</span><span class="p">))):</span>
                <span class="n">a</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span><span class="p">,</span> <span class="n">loc</span><span class="p">)))</span>

        <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Found </span><span class="si">%d</span><span class="s2"> cases ... &quot;</span> <span class="o">%</span> <span class="n">num_samples</span><span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">initialize_storage</span><span class="p">()</span>

        <span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Start loading cases ... &quot;</span><span class="p">)</span>
        
        <span class="n">total_num_loaded</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="k">for</span> <span class="n">loc</span> <span class="ow">in</span> <span class="n">locations</span><span class="p">:</span>
            <span class="k">if</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span><span class="p">,</span> <span class="n">loc</span><span class="p">))):</span>
                <span class="n">total_num_loaded</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_one_loc</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">total_num_loaded</span><span class="p">,</span> <span class="n">t0</span><span class="p">)</span>                                          
        
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total samples loaded </span><span class="si">%d</span><span class="s2"> &quot;</span> <span class="o">%</span> <span class="n">total_num_loaded</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">initialize_storage</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">aif</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lv_rv_masks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lv_masks</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">names</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">def</span> <span class="nf">load_one_data</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">f_prefix</span><span class="p">):</span>
        
        <span class="n">f_name</span> <span class="o">=</span> <span class="n">f_prefix</span> <span class="o">+</span> <span class="s1">&#39;.npy&#39;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">f_name</span><span class="p">))</span>                    
                       
        <span class="c1"># print (&#39;Loaded &#39;, f_name, data.shape)</span>
        
        <span class="k">return</span> <span class="n">data</span>
    
    <span class="k">def</span> <span class="nf">load_one_loc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loc</span><span class="p">,</span> <span class="n">total_num_loaded</span><span class="p">,</span> <span class="n">t0</span><span class="p">):</span>      
        
        <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        
        <span class="n">a</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span><span class="p">,</span> <span class="n">loc</span><span class="p">))</span>
        <span class="n">num_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;---&gt; Start loading &#39;</span><span class="p">,</span> <span class="n">loc</span><span class="p">)</span>
        <span class="n">tq</span> <span class="o">=</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">total</span><span class="o">=</span><span class="p">(</span><span class="n">num_samples</span><span class="p">),</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">a</span><span class="p">):</span>      
            
            <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">            if (ii&gt;30):</span>
<span class="sd">                break</span>
<span class="sd">            &#39;&#39;&#39;</span>
            
            <span class="n">name</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
            <span class="c1">#print(&#39;------&gt; Start loading %d out of %d, %s&#39; % (ii, num_samples, name))</span>

            <span class="n">tq</span><span class="o">.</span><span class="n">set_description</span><span class="p">(</span><span class="s1">&#39;loading </span><span class="si">{}</span><span class="s1">, total </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ii</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">))</span>
            
            <span class="k">try</span><span class="p">:</span>
                <span class="n">Gd</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_one_data</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;aif_scc&#39;</span><span class="p">)</span>
                <span class="k">try</span><span class="p">:</span>
                    <span class="n">lv_rv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_one_data</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;aif_masks_final&#39;</span><span class="p">)</span>                    
                <span class="k">except</span><span class="p">:</span>
                    <span class="n">lv_rv</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">load_one_data</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="s1">&#39;aif_masks&#39;</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;------&gt; Failed to load </span><span class="si">%d</span><span class="s1"> out of </span><span class="si">%d</span><span class="s1">, </span><span class="si">%s</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">ii</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span>
                <span class="k">continue</span>

            <span class="n">RO</span><span class="p">,</span> <span class="n">E1</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">Gd</span><span class="o">.</span><span class="n">shape</span>
                
            <span class="k">if</span><span class="p">(</span><span class="n">N</span><span class="o">&lt;</span><span class="bp">self</span><span class="o">.</span><span class="n">min_reps</span><span class="p">):</span>
                <span class="n">new_Gd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">RO</span><span class="p">,</span> <span class="n">E1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_reps</span><span class="p">))</span>
                <span class="n">new_Gd</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">:</span><span class="n">N</span><span class="p">]</span> <span class="o">=</span> <span class="n">Gd</span>
                <span class="n">f</span> <span class="o">=</span> <span class="n">Gd</span><span class="p">[:,:,</span><span class="n">N</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
                <span class="n">new_Gd</span><span class="p">[:,:,</span><span class="n">N</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">min_reps</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dstack</span><span class="p">([</span><span class="n">f</span><span class="p">]</span><span class="o">*</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">min_reps</span><span class="o">-</span><span class="n">N</span><span class="p">))</span>
                <span class="n">Gd</span> <span class="o">=</span> <span class="n">new_Gd</span>
            
            <span class="k">if</span><span class="p">(</span><span class="n">N</span><span class="o">&gt;</span><span class="bp">self</span><span class="o">.</span><span class="n">min_reps</span><span class="p">):</span>
                <span class="n">Gd</span> <span class="o">=</span> <span class="n">Gd</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">min_reps</span><span class="p">]</span>
            
            <span class="k">if</span><span class="p">(</span><span class="n">E1</span><span class="o">&gt;</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">):</span>
                <span class="n">s</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">E1</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">Gd</span> <span class="o">=</span> <span class="n">Gd</span><span class="p">[:,</span><span class="n">s</span><span class="p">:</span><span class="n">s</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,:]</span>
                <span class="n">lv_rv</span> <span class="o">=</span> <span class="n">lv_rv</span><span class="p">[:,</span><span class="n">s</span><span class="p">:</span><span class="n">s</span><span class="o">+</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">]</span>
                
            <span class="k">if</span><span class="p">(</span><span class="n">E1</span><span class="o">&lt;</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">):</span>
                <span class="n">s</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="o">-</span><span class="n">E1</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
                <span class="n">new_Gd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">RO</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">min_reps</span><span class="p">))</span>
                <span class="n">new_Gd</span><span class="p">[:,</span><span class="n">s</span><span class="p">:</span><span class="n">s</span><span class="o">+</span><span class="n">E1</span><span class="p">,:]</span> <span class="o">=</span> <span class="n">Gd</span>                
                <span class="n">Gd</span> <span class="o">=</span> <span class="n">new_Gd</span>
                                
                <span class="n">new_lv_rv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">RO</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W</span><span class="p">))</span>
                <span class="n">new_lv_rv</span><span class="p">[:,</span><span class="n">s</span><span class="p">:</span><span class="n">s</span><span class="o">+</span><span class="n">E1</span><span class="p">]</span> <span class="o">=</span> <span class="n">lv_rv</span>
                <span class="n">lv_rv</span> <span class="o">=</span> <span class="n">new_lv_rv</span>                
            
            <span class="n">RO</span><span class="p">,</span> <span class="n">E1</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">Gd</span><span class="o">.</span><span class="n">shape</span>
            <span class="k">if</span><span class="p">(</span><span class="n">RO</span><span class="o">!=</span><span class="mi">64</span> <span class="ow">or</span> <span class="n">E1</span><span class="o">!=</span><span class="mi">48</span> <span class="ow">or</span> <span class="n">N</span><span class="o">!=</span><span class="mi">64</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&gt; incorrect Gd shape : &#39;</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
                <span class="k">continue</span>
            
            <span class="n">Gd</span> <span class="o">=</span> <span class="n">Gd</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">Gd</span><span class="p">)</span>
            <span class="n">Gd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">Gd</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
                
            <span class="n">lv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">lv_rv</span><span class="p">)</span>
            <span class="n">lv</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">lv_rv</span><span class="o">==</span><span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mi">1</span>
                
            <span class="n">lv_rv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">lv_rv</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lv_rv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lv_rv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
            <span class="n">lv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">lv</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">lv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">lv</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
        
            <span class="bp">self</span><span class="o">.</span><span class="n">aif</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Gd</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lv_rv_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lv_rv</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">lv_masks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">lv</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

            <span class="c1">#print(&#39;     aif data : &#39;, Gd.shape)</span>
            <span class="c1">#print(&#39;     lv_rv mask : &#39;, lv_rv.shape)</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
                
            <span class="n">total_num_loaded</span> <span class="o">+=</span> <span class="mi">1</span>
                
            <span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
            
            <span class="n">tq</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">tq</span><span class="o">.</span><span class="n">set_postfix</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;</span><span class="si">{:.2f}</span><span class="s1">s&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">t1</span><span class="o">-</span><span class="n">t0</span><span class="p">))</span>
                
            <span class="c1">#print(&quot;             Time from starting : %f seconds ... \n&quot; % (t1-t0))</span>
           
        <span class="n">str_after_loading</span> <span class="o">=</span> <span class="s1">&#39;    Finish loading </span><span class="si">%s</span><span class="s1"> --- Total </span><span class="si">%d</span><span class="s1"> samples -- In </span><span class="si">%.2f</span><span class="s1"> seconds&#39;</span> <span class="o">%</span> <span class="p">(</span><span class="n">loc</span><span class="p">,</span> <span class="n">num_samples</span><span class="p">,</span> <span class="n">t1</span><span class="o">-</span><span class="n">t0</span><span class="p">)</span>
        <span class="n">tq</span><span class="o">.</span><span class="n">set_postfix_str</span><span class="p">(</span><span class="n">str_after_loading</span><span class="p">)</span>
        
        <span class="n">tq</span><span class="o">.</span><span class="n">close</span><span class="p">()</span> 
            
        <span class="k">return</span> <span class="n">total_num_loaded</span>
    
    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aif</span><span class="p">)</span>

    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">):</span>
        
        <span class="k">if</span> <span class="n">idx</span> <span class="o">&gt;=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aif</span><span class="p">):</span>
            <span class="k">raise</span> <span class="s2">&quot;invalid index&quot;</span>
        
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">which_mask</span> <span class="o">==</span> <span class="s1">&#39;lv_rv&#39;</span><span class="p">):</span>            
            <span class="n">sample</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aif</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">lv_rv_masks</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">names</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
            
        <span class="k">if</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">which_mask</span> <span class="o">==</span> <span class="s1">&#39;lv&#39;</span><span class="p">):</span>            
            <span class="n">sample</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aif</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">lv_masks</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">names</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>
            
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">:</span>
            <span class="n">sample</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">sample</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">sample</span>    
    
    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;Perfusion AIF Dataset</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="nb">str</span> <span class="o">+=</span> <span class="s2">&quot;  image root: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">img_dir</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="nb">str</span> <span class="o">+=</span> <span class="s2">&quot;  Number of samples: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aif</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="nb">str</span> <span class="o">+=</span> <span class="s2">&quot;  Number of masks: </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lv_rv_masks</span><span class="p">)</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">aif</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="nb">str</span> <span class="o">+=</span> <span class="s2">&quot;  image shape: </span><span class="si">%d</span><span class="s2"> </span><span class="si">%d</span><span class="s2"> </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">aif</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="nb">str</span> <span class="o">+=</span> <span class="s2">&quot;  myo mask shape: </span><span class="si">%d</span><span class="s2"> </span><span class="si">%d</span><span class="s2"> </span><span class="si">%d</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="bp">self</span><span class="o">.</span><span class="n">lv_rv_masks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="s2">&quot;</span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="k">return</span> <span class="nb">str</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">perf_aif_dataset</span> <span class="o">=</span> <span class="n">PerfAIFDataset</span><span class="p">(</span><span class="n">img_dir</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Done&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Found 3 cases ... 
Start loading cases ... 
---&gt; Start loading  aif
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="d91c2214-347a-4d6c-9e13-36b79feae5b2"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#d91c2214-347a-4d6c-9e13-36b79feae5b2');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "e51109e68dc24c0db653be674a69de84", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total samples loaded 3 
Done
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Perfusion AIF Dataset
  image root: ./data
  Number of samples: 3
  Number of masks: 3
  image shape: 64 64 48
  myo mask shape: 1 64 48

</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">which_mask</span> <span class="o">=</span> <span class="s1">&#39;lv_rv&#39;</span>


<span class="n">B</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="p">)</span>

<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">Gd</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="n">perf_aif_dataset</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
    <span class="n">N</span><span class="p">,</span> <span class="n">RO</span><span class="p">,</span> <span class="n">E1</span> <span class="o">=</span> <span class="n">Gd</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span><span class="p">(</span><span class="n">RO</span><span class="o">!=</span><span class="mi">64</span> <span class="ow">or</span> <span class="n">E1</span><span class="o">!=</span><span class="mi">48</span> <span class="ow">or</span> <span class="n">N</span><span class="o">!=</span><span class="mi">64</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&gt; incorrect Gd shape : &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">Gd</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">RO</span><span class="p">,</span> <span class="n">E1</span> <span class="o">=</span> <span class="n">masks</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">if</span><span class="p">(</span><span class="n">RO</span><span class="o">!=</span><span class="mi">64</span> <span class="ow">or</span> <span class="n">E1</span><span class="o">!=</span><span class="mi">48</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;--&gt; incorrect masks shape : &#39;</span><span class="p">,</span> <span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">masks</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Check-to-see-if-data-loaded-properly">Check to see if data loaded properly<a class="anchor-link" href="#Check-to-see-if-data-loaded-properly"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">B</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="n">ni</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>
<span class="n">nm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>

<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">B</span><span class="p">):</span>
    <span class="n">images</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="n">perf_aif_dataset</span><span class="p">[</span><span class="n">n</span><span class="p">]</span>
    <span class="n">ni</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
    <span class="n">nm</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">masks</span><span class="p">)</span>

    <span class="k">if</span><span class="p">(</span><span class="n">ni</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">names</span><span class="p">,</span> <span class="n">ni</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>    
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ni</span><span class="p">,</span> <span class="n">nm</span><span class="p">,</span> <span class="s1">&#39;bo&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>3
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&lt;matplotlib.lines.Line2D at 0x21c76068048&gt;]</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../../images/03/deep_learning/aif_detection/Perf_AIF_LV_detection_11_2.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="p">)</span>
<span class="n">NUM_TRAIN</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span>

<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>

<span class="n">loader_for_train</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                          <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="o">.</span><span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">NUM_TRAIN</span><span class="p">)))</span>

<span class="n">loader_for_val</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                        <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="o">.</span><span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">NUM_TRAIN</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="p">))))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Perfusion AIF Dataset
  image root: ./data
  Number of samples: 3
  Number of masks: 3
  image shape: 64 64 48
  myo mask shape: 1 64 48

</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">iter_train</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="n">loader_for_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">iter_train</span><span class="p">)</span>
<span class="n">images</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="n">iter_train</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">masks</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">ia</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ia</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">masks</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">cmr_ml_utils_plotting</span><span class="o">.</span><span class="n">plot_image_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">images</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">:</span><span class="mi">4</span><span class="p">,:,:]),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span><span class="mi">8</span><span class="p">])</span>
    
<span class="n">a</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">cmr_ml_utils_plotting</span><span class="o">.</span><span class="n">plot_image_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">masks</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">)),</span> <span class="n">columns</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x0000021C773A5348&gt;
torch.Size([2, 64, 64, 48])
torch.Size([2, 1, 64, 48])
torch.Size([64, 48, 64, 2])
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../../images/03/deep_learning/aif_detection/Perf_AIF_LV_detection_13_1.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../../images/03/deep_learning/aif_detection/Perf_AIF_LV_detection_13_2.png"
>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../../images/03/deep_learning/aif_detection/Perf_AIF_LV_detection_13_3.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Construct-data-loaders">Construct data loaders<a class="anchor-link" href="#Construct-data-loaders"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">USE_GPU</span> <span class="o">=</span> <span class="kc">True</span>

<span class="k">if</span> <span class="n">USE_GPU</span> <span class="ow">and</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;using device:&#39;</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Let&#39;s use&quot;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">(),</span> <span class="s2">&quot;GPUs!&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>using device: cpu
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Data-augmentation">Data augmentation<a class="anchor-link" href="#Data-augmentation"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">RandomFlip1stDim</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Randomly flip the first dimension of numpy array.</span>
<span class="sd">    Args:</span>
<span class="sd">        p (float): probability of the image being flipped. Default value is 0.5</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            img ([N RO E1 ... ]): Image to be flipped.</span>
<span class="sd">        Returns:</span>
<span class="sd">            res: Randomly flipped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1">#print(img[0].shape)</span>
        <span class="c1">#print(img[1].shape)</span>
            
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">:</span> 
                                
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flipud</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            
            <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">flipud</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="k">return</span> <span class="p">(</span> <span class="n">a</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">b</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">img</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">&#39;(p=</span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
    
<span class="k">class</span> <span class="nc">RandomFlip2ndDim</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Randomly flip the second dimension of numpy array.</span>
<span class="sd">    Args:</span>
<span class="sd">        p (float): probability of the image being flipped. Default value is 0.5</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">p</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Args:</span>
<span class="sd">            img ([N RO E1 ... ]): Image to be flipped.</span>
<span class="sd">        Returns:</span>
<span class="sd">            res: Randomly flipped image.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">:</span>    
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fliplr</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            
            <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">img</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">fliplr</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
            <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
            <span class="k">return</span> <span class="p">(</span> <span class="n">a</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">b</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="n">img</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span>

    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span> <span class="o">+</span> <span class="s1">&#39;(p=</span><span class="si">{}</span><span class="s1">)&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">ndimage</span>

<span class="c1"># probs should be a 64x48 torch tensor</span>
<span class="k">def</span> <span class="nf">adaptive_thresh_cpu</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">p_thresh</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">p_thresh_max</span><span class="o">=</span><span class="mf">0.988</span><span class="p">):</span>
    <span class="c1"># Try regular adaptive thresholding first</span>
    <span class="c1">#p_thresh_max  = 0.988 # &lt;-- Should not be too close to 1 to ensure while loop does not go over.</span>

    <span class="n">p_thresh_incr</span> <span class="o">=</span> <span class="mf">0.01</span>
    <span class="c1">#p_thresh = 0.5</span>

    <span class="n">RO</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">E1</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">number_of_blobs</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
        <span class="n">blobs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">RO</span><span class="p">,</span><span class="n">E1</span><span class="p">))</span>
        <span class="k">while</span> <span class="n">number_of_blobs</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">p_thresh</span> <span class="o">&lt;</span> <span class="n">p_thresh_max</span><span class="p">:</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">probs</span> <span class="o">&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">probs</span><span class="p">)</span> <span class="o">*</span> <span class="n">p_thresh</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
            <span class="n">blobs</span><span class="p">,</span> <span class="n">number_of_blobs</span> <span class="o">=</span> <span class="n">ndimage</span><span class="o">.</span><span class="n">label</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
            <span class="n">p_thresh</span> <span class="o">+=</span> <span class="n">p_thresh_incr</span>  <span class="c1"># &lt;-- Note this line can lead to float drift.</span>
    
        <span class="k">if</span><span class="p">(</span><span class="n">number_of_blobs</span> <span class="o">==</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">mask</span>

        <span class="k">if</span><span class="p">(</span><span class="n">number_of_blobs</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">RO</span><span class="p">,</span> <span class="n">E1</span><span class="p">))</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;adaptive_thresh_cpu, did not find any blobs ... &quot;</span><span class="p">,</span> <span class="n">file</span><span class="o">=</span><span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="p">)</span>
            <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
            <span class="k">return</span> <span class="n">mask</span>

        <span class="c1">## If we are here then we cannot isolate a singular blob as the LV.</span>
        <span class="c1">## Select the largest blob as the final mask.</span>
        <span class="n">biggest_blob</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">RO</span><span class="p">,</span><span class="n">E1</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">number_of_blobs</span><span class="p">):</span>
            <span class="n">one_blob</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">((</span><span class="n">blobs</span> <span class="o">==</span> <span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
            <span class="n">area</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">one_blob</span><span class="p">)</span>
            <span class="k">if</span><span class="p">(</span><span class="n">area</span> <span class="o">&gt;</span> <span class="n">biggest_blob</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
                <span class="n">biggest_blob</span> <span class="o">=</span> <span class="p">(</span><span class="n">area</span><span class="p">,</span> <span class="n">one_blob</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">biggest_blob</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

    <span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Error happened in adaptive_thresh_cpu ...&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">e</span><span class="p">)</span>
        <span class="n">sys</span><span class="o">.</span><span class="n">stderr</span><span class="o">.</span><span class="n">flush</span><span class="p">()</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">RO</span><span class="p">,</span><span class="n">E1</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">mask</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">compute_dice_scores</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">loader</span><span class="p">,</span> <span class="n">aif_trainer</span><span class="p">,</span> <span class="n">binary_seg</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="c1"># get dice for all LV in validation set</span>
    <span class="n">dice_scores</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">cases</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> 

    <span class="n">ind</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="n">best_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>  <span class="c1"># set model to evaluation mode</span>
           
    <span class="k">for</span> <span class="n">t</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">names</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>        

        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">aif_trainer</span><span class="o">.</span><span class="n">x_dtype</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span> 
        <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">aif_trainer</span><span class="o">.</span><span class="n">y_dtype</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
       
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="n">best_model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="c1"># loss = aif_trainer.compute_loss(scores, y)</span>

        <span class="k">if</span><span class="p">(</span><span class="n">binary_seg</span><span class="p">):</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">probs</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>

        <span class="n">probs</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>

        <span class="n">N</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        
        <span class="n">aif_mask</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>        
            
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
            
            <span class="k">if</span><span class="p">(</span><span class="n">binary_seg</span><span class="p">):</span>
                <span class="n">lv_probs</span> <span class="o">=</span> <span class="n">probs</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">lv_probs</span> <span class="o">=</span> <span class="n">probs</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
            <span class="c1"># lv_mask = training.adaptive_thresh(lv_probs, device=torch.device(&#39;cpu&#39;), p_thresh=0.5)</span>
            <span class="c1">#lv_mask = lv_mask.cpu().detach().numpy()</span>
            
            <span class="c1">#lv_probs = lv_probs.cpu().detach().numpy()</span>
            <span class="c1">#lv_probs = np.squeeze(lv_probs)</span>
            
            <span class="n">lv_probs</span> <span class="o">=</span> <span class="n">lv_probs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
            <span class="n">lv_mask</span> <span class="o">=</span> <span class="n">adaptive_thresh_cpu</span><span class="p">(</span><span class="n">lv_probs</span><span class="p">,</span> <span class="n">p_thresh</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
                        
            <span class="n">lv_mask</span> <span class="o">=</span> <span class="n">lv_mask</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="n">lv_aif_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">lv_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
            <span class="n">lv_aif_mask</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">aif_mask</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="p">:,:]</span><span class="o">==</span><span class="mi">1</span><span class="p">))]</span> <span class="o">=</span> <span class="mi">1</span>

            <span class="n">ds</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">dice</span><span class="p">(</span><span class="n">lv_aif_mask</span><span class="p">,</span> <span class="n">lv_mask</span><span class="p">)</span>

            <span class="k">if</span><span class="p">(</span><span class="n">ds</span><span class="o">&lt;</span><span class="mf">0.1</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">names</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
                <span class="n">curr_probs</span> <span class="o">=</span> <span class="n">probs</span><span class="p">[</span><span class="n">n</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="p">:]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
                <span class="n">curr_probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">curr_probs</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
                <span class="n">a</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">cmr_ml_utils_plotting</span><span class="o">.</span><span class="n">plot_image_array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">curr_probs</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">])</span>
                <span class="n">a</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">cmr_ml_utils_plotting</span><span class="o">.</span><span class="n">plot_image_array</span><span class="p">(</span><span class="n">lv_aif_mask</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">])</span>
                <span class="n">a</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">cmr_ml_utils_plotting</span><span class="o">.</span><span class="n">plot_image_array</span><span class="p">(</span><span class="n">lv_mask</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">])</span>
    
            <span class="n">dice_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ds</span><span class="p">)</span>
            <span class="n">cases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">names</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">dice_scores</span><span class="p">,</span> <span class="n">cases</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">get_failed_cases</span><span class="p">(</span><span class="n">dice_scores</span><span class="p">,</span> <span class="n">cases</span><span class="p">,</span> <span class="n">thres</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">print_failed</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="n">total_samples</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">dice_scores</span><span class="p">)</span>
    <span class="n">sucess_samples</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">failed_cases</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">failed_dices</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">total_samples</span><span class="p">):</span>
        <span class="k">if</span><span class="p">(</span><span class="n">dice_scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">&gt;=</span><span class="n">thres</span><span class="p">):</span>
            <span class="n">sucess_samples</span> <span class="o">=</span> <span class="n">sucess_samples</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span><span class="p">(</span><span class="n">print_failed</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;case </span><span class="si">%s</span><span class="s2">, dice </span><span class="si">%f</span><span class="s2"> &quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">cases</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">dice_scores</span><span class="p">[</span><span class="n">k</span><span class="p">]))</span>
                
            <span class="n">failed_cases</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">cases</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>
            <span class="n">failed_dices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dice_scores</span><span class="p">[</span><span class="n">k</span><span class="p">])</span>

    <span class="n">success_rate</span> <span class="o">=</span> <span class="n">sucess_samples</span><span class="o">/</span><span class="n">total_samples</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Total test samples is &quot;</span><span class="p">,</span> <span class="n">total_samples</span><span class="p">)</span>  
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Success rate is &quot;</span><span class="p">,</span> <span class="n">success_rate</span><span class="p">)</span>  
    
    <span class="k">return</span> <span class="n">failed_cases</span><span class="p">,</span> <span class="n">failed_dices</span><span class="p">,</span> <span class="n">success_rate</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">load_apply_model_multi_class</span><span class="p">(</span><span class="n">img_dir</span><span class="p">,</span> <span class="n">case_name</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
    
    <span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">img_dir</span><span class="p">,</span> <span class="n">case_name</span><span class="p">)</span>

    <span class="n">model_device</span> <span class="o">=</span> <span class="n">device</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="n">data_dir</span><span class="p">)</span>

    <span class="n">Gd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;aif.npy&#39;</span><span class="p">))</span>
    <span class="n">RO</span><span class="p">,</span> <span class="n">E1</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="n">Gd</span><span class="o">.</span><span class="n">shape</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">aif_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;aif_masks_final.npy&#39;</span><span class="p">))</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="n">aif_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;aif_masks.npy&#39;</span><span class="p">))</span>

    <span class="n">Gd</span> <span class="o">=</span> <span class="n">Gd</span><span class="p">[:,:,</span><span class="mi">0</span><span class="p">:</span><span class="mi">64</span><span class="p">]</span>
    <span class="n">s</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="n">E1</span><span class="o">-</span><span class="mi">48</span><span class="p">)</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">Gd</span> <span class="o">=</span> <span class="n">Gd</span><span class="p">[:,</span><span class="n">s</span><span class="p">:</span><span class="n">s</span><span class="o">+</span><span class="mi">48</span><span class="p">,:]</span>

    <span class="n">Gd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">Gd</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">Gd</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Gd</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">Gd</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">Gd</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">Gd</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]))</span>
    <span class="n">Gd</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">Gd</span><span class="p">)</span>

    <span class="n">aif</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">(</span><span class="n">Gd</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
    <span class="n">aif</span> <span class="o">=</span> <span class="n">aif</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">model_device</span><span class="p">)</span>
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> 
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">aif</span><span class="p">)</span>

    <span class="n">m</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>

    <span class="n">probs</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
    
    <span class="n">lv_probs</span> <span class="o">=</span> <span class="n">probs</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
    <span class="n">lv_mask</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">adaptive_thresh</span><span class="p">(</span><span class="n">lv_probs</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">),</span> <span class="n">p_thresh</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
    
    <span class="n">lv_mask</span> <span class="o">=</span> <span class="n">lv_mask</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">probs</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
    <span class="n">probs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)))</span>
    
    <span class="n">a</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">cmr_ml_utils_plotting</span><span class="o">.</span><span class="n">plot_image_array</span><span class="p">(</span><span class="n">probs</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">])</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">cmr_ml_utils_plotting</span><span class="o">.</span><span class="n">plot_image_array</span><span class="p">(</span><span class="n">aif_mask</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">])</span>
    <span class="n">a</span> <span class="o">=</span> <span class="n">utils</span><span class="o">.</span><span class="n">cmr_ml_utils_plotting</span><span class="o">.</span><span class="n">plot_image_array</span><span class="p">(</span><span class="n">lv_mask</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span><span class="mi">16</span><span class="p">])</span>
    
    <span class="k">return</span> <span class="n">probs</span><span class="p">,</span> <span class="n">lv_mask</span><span class="p">,</span> <span class="n">aif_mask</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train-with-multi-class-trainer">Train with multi-class trainer<a class="anchor-link" href="#Train-with-multi-class-trainer"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># data augmenation for random flipping</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">RandomFlip1stDim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">RandomFlip2ndDim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)])</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">which_mask</span> <span class="o">=</span> <span class="s1">&#39;lv_rv&#39;</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">class_for_accu</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="n">class_weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>
<span class="n">class_weights</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">p_thres</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">which_mask</span><span class="p">)</span>

<span class="n">sample</span> <span class="o">=</span> <span class="n">perf_aif_dataset</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>lv_rv
(1, 64, 48)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.image.AxesImage at 0x21c781dd288&gt;</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../../images/03/deep_learning/aif_detection/Perf_AIF_LV_detection_26_2.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">images</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="n">iter_train</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

<span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">RO</span><span class="p">,</span> <span class="n">E1</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">shape</span>

<span class="nb">print</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">masks</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">masks</span><span class="p">))</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">images</span><span class="p">[:,</span><span class="mi">32</span><span class="p">,:,:]</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">RO</span><span class="p">,</span> <span class="n">E1</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">show</span><span class="p">(</span><span class="n">make_grid</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">double</span><span class="p">(),</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">scale_each</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">show</span><span class="p">(</span><span class="n">make_grid</span><span class="p">(</span><span class="n">masks</span><span class="o">.</span><span class="n">double</span><span class="p">(),</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scale_each</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">masks</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-intense-fg ansi-bold">---------------------------------------------------------------------------</span>
<span class="ansi-red-intense-fg ansi-bold">StopIteration</span>                             Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">&lt;ipython-input-24-c99a52f47bb6&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">----&gt; 1</span><span class="ansi-yellow-intense-fg ansi-bold"> </span>images<span class="ansi-yellow-intense-fg ansi-bold">,</span> masks<span class="ansi-yellow-intense-fg ansi-bold">,</span> names <span class="ansi-yellow-intense-fg ansi-bold">=</span> iter_train<span class="ansi-yellow-intense-fg ansi-bold">.</span>next<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">      2</span> 
<span class="ansi-green-fg">      3</span> B<span class="ansi-yellow-intense-fg ansi-bold">,</span> C<span class="ansi-yellow-intense-fg ansi-bold">,</span> RO<span class="ansi-yellow-intense-fg ansi-bold">,</span> E1 <span class="ansi-yellow-intense-fg ansi-bold">=</span> images<span class="ansi-yellow-intense-fg ansi-bold">.</span>shape
<span class="ansi-green-fg">      4</span> 
<span class="ansi-green-fg">      5</span> print<span class="ansi-yellow-intense-fg ansi-bold">(</span>images<span class="ansi-yellow-intense-fg ansi-bold">.</span>shape<span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-green-intense-fg ansi-bold">~\Anaconda3\envs\qperf\lib\site-packages\torch\utils\data\dataloader.py</span> in <span class="ansi-cyan-fg">__next__</span><span class="ansi-blue-intense-fg ansi-bold">(self)</span>
<span class="ansi-green-fg">    433</span>         <span class="ansi-green-intense-fg ansi-bold">if</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_sampler_iter <span class="ansi-green-intense-fg ansi-bold">is</span> <span class="ansi-green-intense-fg ansi-bold">None</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">    434</span>             self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_reset<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 435</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>data <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_next_data<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    436</span>         self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_num_yielded <span class="ansi-yellow-intense-fg ansi-bold">+=</span> <span class="ansi-cyan-intense-fg ansi-bold">1</span>
<span class="ansi-green-fg">    437</span>         <span class="ansi-green-intense-fg ansi-bold">if</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_dataset_kind <span class="ansi-yellow-intense-fg ansi-bold">==</span> _DatasetKind<span class="ansi-yellow-intense-fg ansi-bold">.</span>Iterable <span class="ansi-green-intense-fg ansi-bold">and</span><span class="ansi-red-fg"> </span><span class="ansi-red-fg">\</span>

<span class="ansi-green-intense-fg ansi-bold">~\Anaconda3\envs\qperf\lib\site-packages\torch\utils\data\dataloader.py</span> in <span class="ansi-cyan-fg">_next_data</span><span class="ansi-blue-intense-fg ansi-bold">(self)</span>
<span class="ansi-green-fg">    472</span> 
<span class="ansi-green-fg">    473</span>     <span class="ansi-green-intense-fg ansi-bold">def</span> _next_data<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 474</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>index <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_next_index<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>  <span class="ansi-red-intense-fg ansi-bold"># may raise StopIteration</span>
<span class="ansi-green-fg">    475</span>         data <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_dataset_fetcher<span class="ansi-yellow-intense-fg ansi-bold">.</span>fetch<span class="ansi-yellow-intense-fg ansi-bold">(</span>index<span class="ansi-yellow-intense-fg ansi-bold">)</span>  <span class="ansi-red-intense-fg ansi-bold"># may raise StopIteration</span>
<span class="ansi-green-fg">    476</span>         <span class="ansi-green-intense-fg ansi-bold">if</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_pin_memory<span class="ansi-yellow-intense-fg ansi-bold">:</span>

<span class="ansi-green-intense-fg ansi-bold">~\Anaconda3\envs\qperf\lib\site-packages\torch\utils\data\dataloader.py</span> in <span class="ansi-cyan-fg">_next_index</span><span class="ansi-blue-intense-fg ansi-bold">(self)</span>
<span class="ansi-green-fg">    425</span> 
<span class="ansi-green-fg">    426</span>     <span class="ansi-green-intense-fg ansi-bold">def</span> _next_index<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 427</span><span class="ansi-yellow-intense-fg ansi-bold">         </span><span class="ansi-green-intense-fg ansi-bold">return</span> next<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_sampler_iter<span class="ansi-yellow-intense-fg ansi-bold">)</span>  <span class="ansi-red-intense-fg ansi-bold"># may raise StopIteration</span>
<span class="ansi-green-fg">    428</span> 
<span class="ansi-green-fg">    429</span>     <span class="ansi-green-intense-fg ansi-bold">def</span> _next_data<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>

<span class="ansi-red-intense-fg ansi-bold">StopIteration</span>: </pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">perform_training</span><span class="p">(</span><span class="n">hyperpara</span><span class="p">,</span> <span class="n">perf_aif_dataset</span><span class="p">,</span> <span class="n">loader_for_train</span><span class="p">,</span> <span class="n">loader_for_val</span><span class="p">):</span>
    
    <span class="n">num_epochs</span> <span class="o">=</span> <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;num_epochs&#39;</span><span class="p">]</span>
    <span class="n">print_every</span> <span class="o">=</span> <span class="mi">100000</span>

    <span class="n">inplanes</span> <span class="o">=</span> <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;inplanes&#39;</span><span class="p">]</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;layers&#39;</span><span class="p">]</span>
    <span class="n">layers_planes</span> <span class="o">=</span> <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;layers_planes&#39;</span><span class="p">]</span>
    
    <span class="n">class_weights</span> <span class="o">=</span> <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;class_weights&#39;</span><span class="p">]</span>
    <span class="n">jaccard_weight</span> <span class="o">=</span> <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;jaccard_weight&#39;</span><span class="p">]</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;======================================================&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;num_epochs &#39;</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;inplanes &#39;</span><span class="p">,</span> <span class="n">inplanes</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;layers &#39;</span><span class="p">,</span> <span class="n">layers</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;layers_planes &#39;</span><span class="p">,</span> <span class="n">layers_planes</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;class_weights &#39;</span><span class="p">,</span> <span class="n">class_weights</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;jaccard_weight &#39;</span><span class="p">,</span> <span class="n">jaccard_weight</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;======================================================&#39;</span><span class="p">)</span>
    
    <span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">which_mask</span> <span class="o">=</span> <span class="s1">&#39;lv_rv&#39;</span>
    <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">class_for_accu</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
    <span class="n">p_thres</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.75</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">aif</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">aif</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">GadgetronResUnet18</span><span class="p">(</span><span class="n">F0</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> 
                              <span class="n">inplanes</span><span class="o">=</span><span class="n">inplanes</span><span class="p">,</span> 
                              <span class="n">layers</span><span class="o">=</span><span class="n">layers</span><span class="p">,</span> 
                              <span class="n">layers_planes</span><span class="o">=</span><span class="n">layers_planes</span><span class="p">,</span> 
                              <span class="n">use_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                              <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                              <span class="n">H</span><span class="o">=</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
                              <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;model on multiple GPU ... &quot;</span><span class="p">)</span>

    <span class="n">patience</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">factor</span> <span class="o">=</span> <span class="mf">0.5</span>
    <span class="n">cooldown</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="n">min_lr</span> <span class="o">=</span> <span class="mf">1e-7</span>

    <span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1"># optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay, nesterov=True)</span>

    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="n">patience</span><span class="p">,</span> <span class="n">cooldown</span><span class="o">=</span><span class="n">cooldown</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="n">min_lr</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">CW</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">num_classes</span><span class="p">)</span>
    <span class="n">CW</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">class_weights</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">LossMulti</span><span class="p">(</span><span class="n">class_weights</span><span class="o">=</span><span class="n">CW</span><span class="p">,</span> <span class="n">jaccard_weight</span><span class="o">=</span><span class="n">jaccard_weight</span><span class="p">)</span>

    <span class="n">log_dir</span> <span class="o">=</span> <span class="s1">&#39;aif_training/ResUnet&#39;</span> <span class="o">+</span> <span class="s1">&#39;_lr_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_epochs_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>
    <span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>
    
    <span class="n">aif_trainer</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">GadgetronMultiClassSeg_Perf</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> 
                                   <span class="n">optimizer</span><span class="p">,</span> 
                                   <span class="n">criterion</span><span class="p">,</span> 
                                   <span class="n">loader_for_train</span><span class="p">,</span> 
                                   <span class="n">loader_for_val</span><span class="p">,</span> 
                                   <span class="n">class_for_accu</span><span class="o">=</span><span class="n">class_for_accu</span><span class="p">,</span>
                                   <span class="n">p_thres</span> <span class="o">=</span> <span class="n">p_thres</span><span class="p">,</span>
                                   <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span> 
                                   <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span> 
                                   <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> 
                                   <span class="n">x_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> 
                                   <span class="n">y_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> 
                                   <span class="n">early_stopping_thres</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>                              
                                   <span class="n">print_every</span><span class="o">=</span><span class="n">print_every</span><span class="p">,</span> 
                                   <span class="n">writer</span><span class="o">=</span><span class="n">writer</span><span class="p">,</span> 
                                   <span class="n">model_folder</span><span class="o">=</span><span class="s2">&quot;perf_training/&quot;</span><span class="p">)</span>
    
    
    <span class="n">epochs_traning</span><span class="p">,</span> <span class="n">epochs_validation</span><span class="p">,</span> <span class="n">best_model</span><span class="p">,</span> <span class="n">loss_all</span><span class="p">,</span> <span class="n">epochs_acc_class</span> <span class="o">=</span> <span class="n">aif_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">epoch_to_load</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_model_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    
    <span class="n">dice_scores</span><span class="p">,</span> <span class="n">cases</span> <span class="o">=</span> <span class="n">compute_dice_scores</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">loader_for_val</span><span class="p">,</span> <span class="n">aif_trainer</span><span class="p">)</span>
    <span class="n">failed_cases</span><span class="p">,</span> <span class="n">failed_dices</span><span class="p">,</span> <span class="n">success_rate</span> <span class="o">=</span> <span class="n">get_failed_cases</span><span class="p">(</span><span class="n">dice_scores</span><span class="p">,</span> <span class="n">cases</span><span class="p">,</span> <span class="n">thres</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">print_failed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>   
    <span class="n">scipy</span><span class="o">.</span><span class="n">io</span><span class="o">.</span><span class="n">savemat</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">img_dir</span><span class="p">,</span> <span class="s1">&#39;perf_aif_lv_rv_val_failed.mat&#39;</span><span class="p">),</span> <span class="p">{</span><span class="s2">&quot;cases&quot;</span><span class="p">:</span><span class="n">failed_cases</span><span class="p">,</span> <span class="s2">&quot;dices&quot;</span><span class="p">:</span><span class="n">failed_dices</span><span class="p">,</span> <span class="s2">&quot;dice_scores&quot;</span><span class="p">:</span><span class="n">dice_scores</span><span class="p">,</span> <span class="s2">&quot;cases&quot;</span><span class="p">:</span><span class="n">cases</span><span class="p">})</span>
    
    <span class="n">dice_scores_train</span><span class="p">,</span> <span class="n">cases_train</span> <span class="o">=</span> <span class="n">compute_dice_scores</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">loader_for_train</span><span class="p">,</span> <span class="n">aif_trainer</span><span class="p">)</span>
    <span class="n">failed_cases_train</span><span class="p">,</span> <span class="n">failed_dices_train</span><span class="p">,</span> <span class="n">success_rate_train</span> <span class="o">=</span> <span class="n">get_failed_cases</span><span class="p">(</span><span class="n">dice_scores_train</span><span class="p">,</span> <span class="n">cases_train</span><span class="p">,</span> <span class="n">thres</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">print_failed</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> 

    <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;best_model&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">best_model</span>
    <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;epochs_traning&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epochs_traning</span>
    <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;epochs_validation&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epochs_validation</span>
    <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;loss_all&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">loss_all</span>
    <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;epochs_acc_class&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epochs_acc_class</span>
    
    <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;dice_scores&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dice_scores</span>
    <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;cases&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cases</span>
    <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;failed_cases&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">failed_cases</span>
    <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;failed_dices&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">failed_dices</span>
    <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;success_rate&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">success_rate</span>
    
    <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;dice_scores_train&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dice_scores</span>
    <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;cases_train&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">cases</span>
    
    <span class="k">return</span> <span class="n">hyperpara</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># hyper parameter search</span>
<span class="n">layers_planes</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">96</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span> <span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">]]</span>
<span class="n">layers</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]]</span>
<span class="n">inplanes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">96</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>

<span class="n">best_success_rate</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">best_hyperpara</span> <span class="o">=</span> <span class="kc">None</span>

<span class="n">hyperpara_all</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers_planes</span><span class="p">)):</span>
    <span class="k">for</span> <span class="n">b</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">inplanes</span><span class="p">)):</span>
            
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-----------------------------------------------&#39;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
            
            <span class="n">hyperpara</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
            
            <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;num_epochs&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">40</span>
            <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;inplanes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">inplanes</span><span class="p">[</span><span class="n">c</span><span class="p">]</span>
            <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;layers&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">layers</span><span class="p">[</span><span class="n">b</span><span class="p">]</span>
            <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;layers_planes&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">layers_planes</span><span class="p">[</span><span class="n">a</span><span class="p">]</span>
    
            <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;class_weights&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">5.0</span>
            <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;jaccard_weight&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.5</span>
            
            <span class="n">k</span> <span class="o">=</span> <span class="mi">12</span>
            <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">256</span>

            <span class="c1"># Chunk into k random sets</span>
            <span class="n">chunks</span> <span class="o">=</span> <span class="n">chunk</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="p">)),</span> <span class="n">k</span><span class="p">)</span>
            <span class="n">listified_chunks</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">chunks</span><span class="p">)</span>

            <span class="n">val_idxs</span> <span class="o">=</span> <span class="n">listified_chunks</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">train_idxs</span> <span class="o">=</span> <span class="n">listified_chunks</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span>
            <span class="n">train_idxs</span> <span class="o">=</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">sublist</span> <span class="ow">in</span> <span class="n">train_idxs</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">sublist</span><span class="p">]</span>

            <span class="n">num_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_idxs</span><span class="p">)</span>
            <span class="n">num_val</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_idxs</span><span class="p">)</span>

            <span class="n">loader_for_train</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                      <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="o">.</span><span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">train_idxs</span><span class="p">))</span>

            <span class="n">loader_for_val</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> 
                                    <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="o">.</span><span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="n">val_idxs</span><span class="p">))</span>

            <span class="n">num_train</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_idxs</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;num_train = </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">num_train</span><span class="p">)</span>
            <span class="n">num_val</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">val_idxs</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;num_val = </span><span class="si">%d</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">num_val</span><span class="p">)</span>
            
            <span class="n">hyperpara</span> <span class="o">=</span> <span class="n">perform_training</span><span class="p">(</span><span class="n">hyperpara</span><span class="p">,</span> <span class="n">perf_aif_dataset</span><span class="p">,</span> <span class="n">loader_for_train</span><span class="p">,</span> <span class="n">loader_for_val</span><span class="p">)</span>
            
            <span class="c1"># print(hyperpara)</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;success rate - &#39;</span><span class="p">,</span> <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;success_rate&#39;</span><span class="p">])</span>
            
            <span class="k">if</span><span class="p">(</span><span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;success_rate&#39;</span><span class="p">]</span><span class="o">&gt;</span><span class="n">best_success_rate</span><span class="p">):</span>
                <span class="n">best_success_rate</span> <span class="o">=</span> <span class="n">hyperpara</span><span class="p">[</span><span class="s1">&#39;success_rate&#39;</span><span class="p">]</span>
                <span class="n">best_hyperpara</span> <span class="o">=</span> <span class="n">hyperpara</span>
                
            <span class="n">hyperpara_all</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">hyperpara</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>-----------------------------------------------
0 0 0
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-intense-fg ansi-bold">---------------------------------------------------------------------------</span>
<span class="ansi-red-intense-fg ansi-bold">NameError</span>                                 Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">&lt;ipython-input-26-c7af734a631f&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-fg">     30</span> 
<span class="ansi-green-fg">     31</span>             <span class="ansi-red-intense-fg ansi-bold"># Chunk into k random sets</span>
<span class="ansi-green-intense-fg ansi-bold">---&gt; 32</span><span class="ansi-yellow-intense-fg ansi-bold">             </span>chunks <span class="ansi-yellow-intense-fg ansi-bold">=</span> chunk<span class="ansi-yellow-intense-fg ansi-bold">(</span>range<span class="ansi-yellow-intense-fg ansi-bold">(</span>len<span class="ansi-yellow-intense-fg ansi-bold">(</span>perf_aif_dataset<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">,</span> k<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     33</span>             listified_chunks <span class="ansi-yellow-intense-fg ansi-bold">=</span> list<span class="ansi-yellow-intense-fg ansi-bold">(</span>chunks<span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">     34</span> 

<span class="ansi-red-intense-fg ansi-bold">NameError</span>: name &#39;chunk&#39; is not defined</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">print_every</span> <span class="o">=</span> <span class="mi">100000</span>

<span class="c1"># resnet</span>
<span class="n">inplanes</span> <span class="o">=</span> <span class="mi">96</span>
<span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">layers_planes</span><span class="o">=</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>
<span class="n">growth_rate</span> <span class="o">=</span> <span class="mi">8</span>

<span class="c1">#dense net</span>
<span class="n">inplanes</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">layers_planes</span><span class="o">=</span><span class="p">[</span><span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">]</span>
<span class="n">growth_rate</span> <span class="o">=</span> <span class="mi">16</span>

<span class="c1"># resnet, small</span>
<span class="n">inplanes</span> <span class="o">=</span> <span class="mi">96</span>
<span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="n">layers_planes</span><span class="o">=</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>
<span class="n">growth_rate</span> <span class="o">=</span> <span class="mi">8</span>

<span class="nb">print</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">aif</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">aif</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">GadgetronResUnet18</span><span class="p">(</span><span class="n">F0</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> 
                          <span class="n">inplanes</span><span class="o">=</span><span class="n">inplanes</span><span class="p">,</span> 
                          <span class="n">layers</span><span class="o">=</span><span class="n">layers</span><span class="p">,</span> 
                          <span class="n">layers_planes</span><span class="o">=</span><span class="n">layers_planes</span><span class="p">,</span> 
                          <span class="n">use_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                          <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                          <span class="n">H</span><span class="o">=</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
                          <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;model on multiple GPU ... &quot;</span><span class="p">)</span>

<span class="n">patience</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">factor</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">cooldown</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">min_lr</span> <span class="o">=</span> <span class="mf">1e-7</span>

<span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay, nesterov=True)</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="n">patience</span><span class="p">,</span> <span class="n">cooldown</span><span class="o">=</span><span class="n">cooldown</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="n">min_lr</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">LossMulti</span><span class="p">(</span><span class="n">class_weights</span><span class="o">=</span><span class="n">class_weights</span><span class="p">,</span> <span class="n">jaccard_weight</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="c1"># criterion = nn.BCEWithLogitsLoss()</span>
<span class="c1"># criterion = nn.BCELoss()</span>

<span class="n">log_dir</span> <span class="o">=</span> <span class="s1">&#39;./aif_training/ResUnet&#39;</span> <span class="o">+</span> <span class="s1">&#39;_lr_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_epochs_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(64, 64, 48)
GadgetronResUnet : F0=64, inplanes=96
------------------------------------------------------------
    GadgetronResUnetInputBlock : input size (64, 64, 48), output size (96, 64, 48) --&gt; (96, 64, 48)
------------------------------------------------------------
    GadgetronResUnet, down layer 0:
        GadgetronResUnet, down layer (64, 48) -&gt; (32, 24)
        GadgetronResUnetBasicBlock : input size (96, 32, 24), output size (128, 32, 24) --&gt; (128, 32, 24)
        GadgetronResUnetBasicBlock : input size (128, 32, 24), output size (128, 32, 24) --&gt; (128, 32, 24)
    GadgetronResUnet, down layer 1:
        GadgetronResUnet, down layer (32, 24) -&gt; (16, 12)
        GadgetronResUnetBasicBlock : input size (128, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
        GadgetronResUnetBasicBlock : input size (128, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
        GadgetronResUnetBasicBlock : input size (128, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
------------------------------------------------------------
    GadgetronResUnet, bridge layer (128, 16, 12) --&gt; (128, 16, 12)
        GadgetronResUnet, down layer (16, 12) -&gt; (8, 6)
        GadgetronResUnetBasicBlock : input size (128, 8, 6), output size (128, 8, 6) --&gt; (128, 8, 6)
        GadgetronResUnetBasicBlock : input size (128, 8, 6), output size (128, 8, 6) --&gt; (128, 8, 6)
        GadgetronResUnetBasicBlock : input size (128, 8, 6), output size (128, 8, 6) --&gt; (128, 8, 6)
------------------------------------------------------------
    GadgetronResUnet, up layer 0:
        GadgetronResUnet_UpSample : input size (256, 8, 6), upsampled size (256, 16, 12)
        GadgetronResUnetBasicBlock : input size (256, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
        GadgetronResUnetBasicBlock : input size (128, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
        GadgetronResUnetBasicBlock : input size (128, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
    GadgetronResUnet, up layer 1:
        GadgetronResUnet_UpSample : input size (256, 16, 12), upsampled size (256, 32, 24)
        GadgetronResUnetBasicBlock : input size (256, 32, 24), output size (96, 32, 24) --&gt; (96, 32, 24)
        GadgetronResUnetBasicBlock : input size (96, 32, 24), output size (96, 32, 24) --&gt; (96, 32, 24)
    GadgetronResUnet, up layer 2:
        GadgetronResUnet_UpSample : input size (192, 32, 24), upsampled size (192, 64, 48)
        GadgetronResUnetBasicBlock : input size (192, 64, 48), output size (96, 64, 48) --&gt; (96, 64, 48)
        GadgetronResUnetBasicBlock : input size (96, 64, 48), output size (96, 64, 48) --&gt; (96, 64, 48)
------------------------------------------------------------
Output layer (96, 64, 48) --&gt; (3, 64, 48)
------------------------------------------------------------
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">aif_trainer</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">GadgetronMultiClassSeg_Perf</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> 
                                   <span class="n">optimizer</span><span class="p">,</span> 
                                   <span class="n">criterion</span><span class="p">,</span> 
                                   <span class="n">loader_for_train</span><span class="p">,</span> 
                                   <span class="n">loader_for_val</span><span class="p">,</span> 
                                   <span class="n">class_for_accu</span><span class="o">=</span><span class="n">class_for_accu</span><span class="p">,</span>
                                   <span class="n">p_thres</span> <span class="o">=</span> <span class="n">p_thres</span><span class="p">,</span>
                                   <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span> 
                                   <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span> 
                                   <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> 
                                   <span class="n">x_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> 
                                   <span class="n">y_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">,</span> 
                                   <span class="n">early_stopping_thres</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>                              
                                   <span class="n">print_every</span><span class="o">=</span><span class="n">print_every</span><span class="p">,</span>
                                   <span class="n">small_data_mode</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
                                   <span class="n">writer</span><span class="o">=</span><span class="n">writer</span><span class="p">,</span> 
                                   <span class="n">model_folder</span><span class="o">=</span><span class="s2">&quot;aif_training/&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">epochs_traning</span><span class="p">,</span> <span class="n">epochs_validation</span><span class="p">,</span> <span class="n">best_model</span><span class="p">,</span> <span class="n">loss_all</span><span class="p">,</span> <span class="n">epochs_acc_class</span> <span class="o">=</span> <span class="n">aif_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">epoch_to_load</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_model_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>50
Start training ... 
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
----------------------------------------
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="643f27a8-ecb4-4a1e-ad34-c2b38952339e"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#643f27a8-ecb4-4a1e-ad34-c2b38952339e');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "7dda11e0e3114874a78eaf21692dbaff", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>    0.43/0.07 seconds for Training/Validation --- Tra acc = 0.0280, Val acc = 0.0226 --- Tra loss = 8.8226, Val loss = 11.4259, --- class acc = 3.030298330486403e-06, 0.04522106423974037
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="a82fbeb7-6813-49ca-87bb-bcb734dcc8e9"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#a82fbeb7-6813-49ca-87bb-bcb734dcc8e9');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "74364740241644d79abc838b219392cb", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>    0.37/0.05 seconds for Training/Validation --- Tra acc = 0.1448, Val acc = 0.0000 --- Tra loss = 0.8061, Val loss = 5.1145, --- class acc = 3.076918346778257e-06, 4.347816684457939e-06
validation accuracy goes way down ... 
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">loss_all</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">500</span><span class="p">,</span><span class="mi">0</span><span class="p">],</span> <span class="n">loss_all</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">500</span><span class="p">,</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&lt;matplotlib.lines.Line2D at 0x21c7842ce88&gt;]</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../../images/03/deep_learning/aif_detection/Perf_AIF_LV_detection_33_1.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">acc_class</span> <span class="o">=</span> <span class="n">aif_trainer</span><span class="o">.</span><span class="n">check_validation_test_accuracy</span><span class="p">(</span><span class="n">loader_for_val</span><span class="p">,</span> <span class="n">best_model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">acc</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">acc_class</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.010955418460071087 15.461913108825684
[2.94117217e-06 2.19078958e-02]
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Train-with-binary-segmenation">Train with binary segmenation<a class="anchor-link" href="#Train-with-binary-segmenation"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># data augmenation for random flipping</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">RandomFlip1stDim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">RandomFlip2ndDim</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)])</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">transform</span> <span class="o">=</span> <span class="n">transform</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">which_mask</span> <span class="o">=</span> <span class="s1">&#39;lv&#39;</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">p_thres</span> <span class="o">=</span> <span class="mf">0.5</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">which_mask</span><span class="p">)</span>

<span class="n">sample</span> <span class="o">=</span> <span class="n">perf_aif_dataset</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">sample</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>lv
(1, 64, 48)
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.image.AxesImage at 0x21c02f91c88&gt;</pre>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">



<div class="output_png output_subarea ">
<img src="../../../images/03/deep_learning/aif_detection/Perf_AIF_LV_detection_39_2.png"
>
</div>

</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">images</span><span class="p">,</span> <span class="n">masks</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="n">iter_train</span><span class="o">.</span><span class="n">next</span><span class="p">()</span>

<span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">RO</span><span class="p">,</span> <span class="n">E1</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">shape</span>

<span class="nb">print</span><span class="p">(</span><span class="n">images</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">masks</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">images</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">masks</span><span class="p">))</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">images</span><span class="p">[:,</span><span class="mi">32</span><span class="p">,:,:]</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="p">(</span><span class="n">B</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">RO</span><span class="p">,</span> <span class="n">E1</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span>
<span class="n">show</span><span class="p">(</span><span class="n">make_grid</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">double</span><span class="p">(),</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">scale_each</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">))</span>
<span class="n">show</span><span class="p">(</span><span class="n">make_grid</span><span class="p">(</span><span class="n">masks</span><span class="o">.</span><span class="n">double</span><span class="p">(),</span> <span class="n">nrow</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">normalize</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">scale_each</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">images</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">masks</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-intense-fg ansi-bold">---------------------------------------------------------------------------</span>
<span class="ansi-red-intense-fg ansi-bold">StopIteration</span>                             Traceback (most recent call last)
<span class="ansi-green-intense-fg ansi-bold">&lt;ipython-input-36-dccc8a7cccf4&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span>
<span class="ansi-green-intense-fg ansi-bold">----&gt; 1</span><span class="ansi-yellow-intense-fg ansi-bold"> </span>images<span class="ansi-yellow-intense-fg ansi-bold">,</span> masks<span class="ansi-yellow-intense-fg ansi-bold">,</span> names <span class="ansi-yellow-intense-fg ansi-bold">=</span> iter_train<span class="ansi-yellow-intense-fg ansi-bold">.</span>next<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">      2</span> 
<span class="ansi-green-fg">      3</span> B<span class="ansi-yellow-intense-fg ansi-bold">,</span> C<span class="ansi-yellow-intense-fg ansi-bold">,</span> RO<span class="ansi-yellow-intense-fg ansi-bold">,</span> E1 <span class="ansi-yellow-intense-fg ansi-bold">=</span> images<span class="ansi-yellow-intense-fg ansi-bold">.</span>shape
<span class="ansi-green-fg">      4</span> 
<span class="ansi-green-fg">      5</span> print<span class="ansi-yellow-intense-fg ansi-bold">(</span>images<span class="ansi-yellow-intense-fg ansi-bold">.</span>shape<span class="ansi-yellow-intense-fg ansi-bold">)</span>

<span class="ansi-green-intense-fg ansi-bold">~\Anaconda3\envs\qperf\lib\site-packages\torch\utils\data\dataloader.py</span> in <span class="ansi-cyan-fg">__next__</span><span class="ansi-blue-intense-fg ansi-bold">(self)</span>
<span class="ansi-green-fg">    433</span>         <span class="ansi-green-intense-fg ansi-bold">if</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_sampler_iter <span class="ansi-green-intense-fg ansi-bold">is</span> <span class="ansi-green-intense-fg ansi-bold">None</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-fg">    434</span>             self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_reset<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 435</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>data <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_next_data<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>
<span class="ansi-green-fg">    436</span>         self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_num_yielded <span class="ansi-yellow-intense-fg ansi-bold">+=</span> <span class="ansi-cyan-intense-fg ansi-bold">1</span>
<span class="ansi-green-fg">    437</span>         <span class="ansi-green-intense-fg ansi-bold">if</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_dataset_kind <span class="ansi-yellow-intense-fg ansi-bold">==</span> _DatasetKind<span class="ansi-yellow-intense-fg ansi-bold">.</span>Iterable <span class="ansi-green-intense-fg ansi-bold">and</span><span class="ansi-red-fg"> </span><span class="ansi-red-fg">\</span>

<span class="ansi-green-intense-fg ansi-bold">~\Anaconda3\envs\qperf\lib\site-packages\torch\utils\data\dataloader.py</span> in <span class="ansi-cyan-fg">_next_data</span><span class="ansi-blue-intense-fg ansi-bold">(self)</span>
<span class="ansi-green-fg">    472</span> 
<span class="ansi-green-fg">    473</span>     <span class="ansi-green-intense-fg ansi-bold">def</span> _next_data<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 474</span><span class="ansi-yellow-intense-fg ansi-bold">         </span>index <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_next_index<span class="ansi-yellow-intense-fg ansi-bold">(</span><span class="ansi-yellow-intense-fg ansi-bold">)</span>  <span class="ansi-red-intense-fg ansi-bold"># may raise StopIteration</span>
<span class="ansi-green-fg">    475</span>         data <span class="ansi-yellow-intense-fg ansi-bold">=</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_dataset_fetcher<span class="ansi-yellow-intense-fg ansi-bold">.</span>fetch<span class="ansi-yellow-intense-fg ansi-bold">(</span>index<span class="ansi-yellow-intense-fg ansi-bold">)</span>  <span class="ansi-red-intense-fg ansi-bold"># may raise StopIteration</span>
<span class="ansi-green-fg">    476</span>         <span class="ansi-green-intense-fg ansi-bold">if</span> self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_pin_memory<span class="ansi-yellow-intense-fg ansi-bold">:</span>

<span class="ansi-green-intense-fg ansi-bold">~\Anaconda3\envs\qperf\lib\site-packages\torch\utils\data\dataloader.py</span> in <span class="ansi-cyan-fg">_next_index</span><span class="ansi-blue-intense-fg ansi-bold">(self)</span>
<span class="ansi-green-fg">    425</span> 
<span class="ansi-green-fg">    426</span>     <span class="ansi-green-intense-fg ansi-bold">def</span> _next_index<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>
<span class="ansi-green-intense-fg ansi-bold">--&gt; 427</span><span class="ansi-yellow-intense-fg ansi-bold">         </span><span class="ansi-green-intense-fg ansi-bold">return</span> next<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">.</span>_sampler_iter<span class="ansi-yellow-intense-fg ansi-bold">)</span>  <span class="ansi-red-intense-fg ansi-bold"># may raise StopIteration</span>
<span class="ansi-green-fg">    428</span> 
<span class="ansi-green-fg">    429</span>     <span class="ansi-green-intense-fg ansi-bold">def</span> _next_data<span class="ansi-yellow-intense-fg ansi-bold">(</span>self<span class="ansi-yellow-intense-fg ansi-bold">)</span><span class="ansi-yellow-intense-fg ansi-bold">:</span>

<span class="ansi-red-intense-fg ansi-bold">StopIteration</span>: </pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">50</span>
<span class="n">print_every</span> <span class="o">=</span> <span class="mi">100000</span>

<span class="n">inplanes</span> <span class="o">=</span> <span class="mi">96</span>
<span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">layers_planes</span><span class="o">=</span><span class="p">[</span><span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">aif</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">C</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">aif</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">shape</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">GadgetronResUnet18</span><span class="p">(</span><span class="n">F0</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> 
                          <span class="n">inplanes</span><span class="o">=</span><span class="n">inplanes</span><span class="p">,</span> 
                          <span class="n">layers</span><span class="o">=</span><span class="n">layers</span><span class="p">,</span> 
                          <span class="n">layers_planes</span><span class="o">=</span><span class="n">layers_planes</span><span class="p">,</span> 
                          <span class="n">use_dropout</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                          <span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> 
                          <span class="n">H</span><span class="o">=</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="o">=</span><span class="n">W</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
                          <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;model on multiple GPU ... &quot;</span><span class="p">)</span>

<span class="n">patience</span> <span class="o">=</span> <span class="mi">10</span>
<span class="n">factor</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">cooldown</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">min_lr</span> <span class="o">=</span> <span class="mf">1e-7</span>

<span class="n">weight_decay</span><span class="o">=</span><span class="mi">0</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">betas</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.999</span><span class="p">),</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-08</span><span class="p">,</span> <span class="n">weight_decay</span><span class="o">=</span><span class="n">weight_decay</span><span class="p">,</span> <span class="n">amsgrad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

<span class="c1"># optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=weight_decay, nesterov=True)</span>

<span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">ReduceLROnPlateau</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="n">patience</span><span class="o">=</span><span class="n">patience</span><span class="p">,</span> <span class="n">cooldown</span><span class="o">=</span><span class="n">cooldown</span><span class="p">,</span> <span class="n">min_lr</span><span class="o">=</span><span class="n">min_lr</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">LossBinary</span><span class="p">(</span><span class="n">jaccard_weight</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="c1"># criterion = training.LossMulti(class_weights=class_weights, jaccard_weight=0.5)</span>

<span class="n">log_dir</span> <span class="o">=</span> <span class="s1">&#39;aif_training/ResUnet&#39;</span> <span class="o">+</span> <span class="s1">&#39;_lr_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">learning_rate</span><span class="p">)</span> <span class="o">+</span> <span class="s1">&#39;_epochs_&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">)</span>
<span class="n">writer</span> <span class="o">=</span> <span class="n">SummaryWriter</span><span class="p">(</span><span class="n">log_dir</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(64, 64, 48)
GadgetronResUnet : F0=64, inplanes=96
------------------------------------------------------------
    GadgetronResUnetInputBlock : input size (64, 64, 48), output size (96, 64, 48) --&gt; (96, 64, 48)
------------------------------------------------------------
    GadgetronResUnet, down layer 0:
        GadgetronResUnet, down layer (64, 48) -&gt; (32, 24)
        GadgetronResUnetBasicBlock : input size (96, 32, 24), output size (128, 32, 24) --&gt; (128, 32, 24)
        GadgetronResUnetBasicBlock : input size (128, 32, 24), output size (128, 32, 24) --&gt; (128, 32, 24)
        GadgetronResUnetBasicBlock : input size (128, 32, 24), output size (128, 32, 24) --&gt; (128, 32, 24)
        GadgetronResUnetBasicBlock : input size (128, 32, 24), output size (128, 32, 24) --&gt; (128, 32, 24)
    GadgetronResUnet, down layer 1:
        GadgetronResUnet, down layer (32, 24) -&gt; (16, 12)
        GadgetronResUnetBasicBlock : input size (128, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
        GadgetronResUnetBasicBlock : input size (128, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
        GadgetronResUnetBasicBlock : input size (128, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
        GadgetronResUnetBasicBlock : input size (128, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
------------------------------------------------------------
    GadgetronResUnet, bridge layer (128, 16, 12) --&gt; (128, 16, 12)
        GadgetronResUnet, down layer (16, 12) -&gt; (8, 6)
        GadgetronResUnetBasicBlock : input size (128, 8, 6), output size (128, 8, 6) --&gt; (128, 8, 6)
        GadgetronResUnetBasicBlock : input size (128, 8, 6), output size (128, 8, 6) --&gt; (128, 8, 6)
        GadgetronResUnetBasicBlock : input size (128, 8, 6), output size (128, 8, 6) --&gt; (128, 8, 6)
        GadgetronResUnetBasicBlock : input size (128, 8, 6), output size (128, 8, 6) --&gt; (128, 8, 6)
------------------------------------------------------------
    GadgetronResUnet, up layer 0:
        GadgetronResUnet_UpSample : input size (256, 8, 6), upsampled size (256, 16, 12)
        GadgetronResUnetBasicBlock : input size (256, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
        GadgetronResUnetBasicBlock : input size (128, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
        GadgetronResUnetBasicBlock : input size (128, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
        GadgetronResUnetBasicBlock : input size (128, 16, 12), output size (128, 16, 12) --&gt; (128, 16, 12)
    GadgetronResUnet, up layer 1:
        GadgetronResUnet_UpSample : input size (256, 16, 12), upsampled size (256, 32, 24)
        GadgetronResUnetBasicBlock : input size (256, 32, 24), output size (96, 32, 24) --&gt; (96, 32, 24)
        GadgetronResUnetBasicBlock : input size (96, 32, 24), output size (96, 32, 24) --&gt; (96, 32, 24)
        GadgetronResUnetBasicBlock : input size (96, 32, 24), output size (96, 32, 24) --&gt; (96, 32, 24)
        GadgetronResUnetBasicBlock : input size (96, 32, 24), output size (96, 32, 24) --&gt; (96, 32, 24)
    GadgetronResUnet, up layer 2:
        GadgetronResUnet_UpSample : input size (192, 32, 24), upsampled size (192, 64, 48)
        GadgetronResUnetBasicBlock : input size (192, 64, 48), output size (96, 64, 48) --&gt; (96, 64, 48)
        GadgetronResUnetBasicBlock : input size (96, 64, 48), output size (96, 64, 48) --&gt; (96, 64, 48)
        GadgetronResUnetBasicBlock : input size (96, 64, 48), output size (96, 64, 48) --&gt; (96, 64, 48)
        GadgetronResUnetBasicBlock : input size (96, 64, 48), output size (96, 64, 48) --&gt; (96, 64, 48)
------------------------------------------------------------
Output layer (96, 64, 48) --&gt; (1, 64, 48)
------------------------------------------------------------
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">aif_trainer</span> <span class="o">=</span> <span class="n">training</span><span class="o">.</span><span class="n">GadgetronTwoClassSeg_PerfAIF</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> 
                                   <span class="n">optimizer</span><span class="p">,</span> 
                                   <span class="n">criterion</span><span class="p">,</span> 
                                   <span class="n">loader_for_train</span><span class="p">,</span> 
                                   <span class="n">loader_for_val</span><span class="p">,</span> 
                                   <span class="n">p_thres</span><span class="o">=</span><span class="n">p_thres</span><span class="p">,</span> 
                                   <span class="n">scheduler</span><span class="o">=</span><span class="n">scheduler</span><span class="p">,</span> 
                                   <span class="n">epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span> 
                                   <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> 
                                   <span class="n">x_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> 
                                   <span class="n">y_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> 
                                   <span class="n">early_stopping_thres</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>                              
                                   <span class="n">print_every</span><span class="o">=</span><span class="n">print_every</span><span class="p">,</span> 
                                   <span class="n">small_data_mode</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> 
                                   <span class="n">writer</span><span class="o">=</span><span class="n">writer</span><span class="p">,</span> 
                                   <span class="n">model_folder</span><span class="o">=</span><span class="s2">&quot;aif_training/&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">epochs_traning</span><span class="p">,</span> <span class="n">epochs_validation</span><span class="p">,</span> <span class="n">best_model</span><span class="p">,</span> <span class="n">loss_all</span><span class="p">,</span> <span class="n">epochs_acc_class</span> <span class="o">=</span> <span class="n">aif_trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">verbose</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">epoch_to_load</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">save_model_epoch</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>50
Start training ... 
Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.001
    weight_decay: 0
)
----------------------------------------
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="f93714ea-b4d9-422a-9376-ae9d4696ed7a"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#f93714ea-b4d9-422a-9376-ae9d4696ed7a');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "571b7c0decb842aa8e2c0a2e8dc3fb5e", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>    0.59/0.08 seconds for Training/Validation --- Tra acc = 0.0215, Val acc = 0.0000 --- Tra loss = 13.0164, Val loss = 32.0950, --- class acc = 2.886002334889781e-07
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="713a12aa-3543-474b-88a0-1165930f5405"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#713a12aa-3543-474b-88a0-1165930f5405');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "f0f648991dde476eb282134d77ed67d9", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>    0.61/0.08 seconds for Training/Validation --- Tra acc = 0.2614, Val acc = 0.0000 --- Tra loss = 1.2310, Val loss = 20.3905, --- class acc = 3.1249951462086756e-06
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="9b74929a-5072-479a-8d93-08b61c4d0bc1"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#9b74929a-5072-479a-8d93-08b61c4d0bc1');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "85e31fd65cc34f3bb4211822c71813d2", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>    0.57/0.07 seconds for Training/Validation --- Tra acc = 0.2917, Val acc = 0.0000 --- Tra loss = 1.1980, Val loss = 20.3905, --- class acc = 3.076918346778257e-06
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="a54dbf48-7dc4-4290-a399-5a5f7f5be200"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#a54dbf48-7dc4-4290-a399-5a5f7f5be200');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "bb9923ee972f491d97317de48e929fd8", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>    0.61/0.10 seconds for Training/Validation --- Tra acc = 0.6075, Val acc = 0.0000 --- Tra loss = 1.0990, Val loss = 20.3905, --- class acc = 3.076918346778257e-06
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="30626d7a-a82b-4521-a934-4acdacc9357e"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#30626d7a-a82b-4521-a934-4acdacc9357e');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "e908ecc767cb49cbb7cb01e6b349bfc6", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>    0.64/0.12 seconds for Training/Validation --- Tra acc = 0.6157, Val acc = 0.0886 --- Tra loss = 1.1251, Val loss = 14.8790, --- class acc = 0.0886077955365181
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="a4016776-44be-4ea7-bc33-613603607d94"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#a4016776-44be-4ea7-bc33-613603607d94');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "395270c2f12a446597665860b8492a3c", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>    0.67/0.10 seconds for Training/Validation --- Tra acc = 0.6705, Val acc = 0.0960 --- Tra loss = 1.1321, Val loss = 13.3621, --- class acc = 0.0960189551115036
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="af9291a9-c328-41cc-bf49-db381a275e38"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#af9291a9-c328-41cc-bf49-db381a275e38');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "7da3282b75ac4f03a516ef7e0a72543e", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>    0.56/0.07 seconds for Training/Validation --- Tra acc = 0.3466, Val acc = 0.1110 --- Tra loss = 1.2686, Val loss = 17.5493, --- class acc = 0.11101490259170532
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="8654715a-9b56-4c6a-a98e-459911beaa44"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#8654715a-9b56-4c6a-a98e-459911beaa44');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "04b7ece5375c46059fa914f5fe5f6467", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>    0.52/0.08 seconds for Training/Validation --- Tra acc = 0.7777, Val acc = 0.0734 --- Tra loss = 0.4687, Val loss = 13.7554, --- class acc = 0.07337300479412079
</pre>
</div>
</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">




 
 
<div id="3930e3e6-adfb-4952-b0b8-086bb2cb1b42"></div>
<div class="output_subarea output_widget_view ">
<script type="text/javascript">
var element = $('#3930e3e6-adfb-4952-b0b8-086bb2cb1b42');
</script>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "471c0e34acbe4c93b9aed9838f4ff9c6", "version_major": 2, "version_minor": 0}
</script>
</div>

</div>
</div>
<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>    0.53/0.10 seconds for Training/Validation --- Tra acc = 0.8076, Val acc = 0.0000 --- Tra loss = 0.4410, Val loss = 28.6724, --- class acc = 3.7878777447986067e-07
validation accuracy goes way down ... 
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Saving-the-model">Saving the model<a class="anchor-link" href="#Saving-the-model"> </a></h2>
</div>
</div>
</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">best_model_cpu</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">module</span>
<span class="k">except</span><span class="p">:</span>
    
    <span class="n">best_model_cpu</span> <span class="o">=</span> <span class="n">best_model</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
    
<span class="nb">print</span><span class="p">(</span><span class="n">best_model_cpu</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>GadgetronResUnet(
  (input_layer): GadgetronResUnetInputBlock(
    (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (down_layers): Sequential(
    (Down layer 0): Sequential(
      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (ResBlock0): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
      (ResBlock1): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
      (ResBlock2): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
      (ResBlock3): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
    )
    (Down layer 1): Sequential(
      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (ResBlock0): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
      (ResBlock1): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
      (ResBlock2): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
      (ResBlock3): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
    )
  )
  (bridge_layer): Sequential(
    (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (ResBlock0): GadgetronResUnetBasicBlock(
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (dp): Dropout2d(p=0.5, inplace=False)
    )
    (ResBlock1): GadgetronResUnetBasicBlock(
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (dp): Dropout2d(p=0.5, inplace=False)
    )
    (ResBlock2): GadgetronResUnetBasicBlock(
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (dp): Dropout2d(p=0.5, inplace=False)
    )
    (ResBlock3): GadgetronResUnetBasicBlock(
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (dp): Dropout2d(p=0.5, inplace=False)
    )
  )
  (up_layers): Sequential(
    (Up layer 0): GadgetronResUnet_UpSample(
      (blocks): Sequential(
        (upsample 0): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 1): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 2): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 3): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
      )
    )
    (Up layer 1): GadgetronResUnet_UpSample(
      (blocks): Sequential(
        (upsample 0): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(256, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 1): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 2): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 3): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
      )
    )
    (Up layer 2): GadgetronResUnet_UpSample(
      (blocks): Sequential(
        (upsample 0): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 1): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 2): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 3): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
      )
    )
  )
  (output_conv): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1))
)
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">datetime</span> <span class="kn">import</span> <span class="n">date</span>
<span class="n">today</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">date</span><span class="o">.</span><span class="n">today</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">today</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">gmtime</span><span class="p">,</span> <span class="n">strftime</span>
<span class="n">moment</span> <span class="o">=</span> <span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y%m</span><span class="si">%d</span><span class="s2">_%H%M%S&quot;</span><span class="p">,</span> <span class="n">gmtime</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">moment</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>2020-12-29
20201229_141838
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_file</span> <span class="o">=</span> <span class="s1">&#39;./deployment/networks/perf_aif_&#39;</span> <span class="o">+</span> <span class="n">perf_aif_dataset</span><span class="o">.</span><span class="n">which_mask</span> <span class="o">+</span> <span class="s1">&#39;_network_&#39;</span> <span class="o">+</span> <span class="n">moment</span> <span class="o">+</span> <span class="s1">&#39;.pbt&#39;</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>./deployment/networks/perf_aif_lv_network_20201229_141838.pbt
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">best_model_cpu</span><span class="p">,</span> <span class="n">model_file</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
</div>

<div class="jb_cell">

<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_loaded</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">model_file</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model_loaded</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="jb_output_wrapper }}">
<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>GadgetronResUnet(
  (input_layer): GadgetronResUnetInputBlock(
    (conv1): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  )
  (down_layers): Sequential(
    (Down layer 0): Sequential(
      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (ResBlock0): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
      (ResBlock1): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
      (ResBlock2): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
      (ResBlock3): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
    )
    (Down layer 1): Sequential(
      (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
      (ResBlock0): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
      (ResBlock1): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
      (ResBlock2): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
      (ResBlock3): GadgetronResUnetBasicBlock(
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu1): ReLU(inplace=True)
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu2): ReLU(inplace=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (dp): Dropout2d(p=0.5, inplace=False)
      )
    )
  )
  (bridge_layer): Sequential(
    (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (ResBlock0): GadgetronResUnetBasicBlock(
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (dp): Dropout2d(p=0.5, inplace=False)
    )
    (ResBlock1): GadgetronResUnetBasicBlock(
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (dp): Dropout2d(p=0.5, inplace=False)
    )
    (ResBlock2): GadgetronResUnetBasicBlock(
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (dp): Dropout2d(p=0.5, inplace=False)
    )
    (ResBlock3): GadgetronResUnetBasicBlock(
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu1): ReLU(inplace=True)
      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu2): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (dp): Dropout2d(p=0.5, inplace=False)
    )
  )
  (up_layers): Sequential(
    (Up layer 0): GadgetronResUnet_UpSample(
      (blocks): Sequential(
        (upsample 0): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 1): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 2): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 3): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
      )
    )
    (Up layer 1): GadgetronResUnet_UpSample(
      (blocks): Sequential(
        (upsample 0): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(256, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 1): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 2): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 3): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
      )
    )
    (Up layer 2): GadgetronResUnet_UpSample(
      (blocks): Sequential(
        (upsample 0): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(192, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 1): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 2): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
        (upsample 3): GadgetronResUnetBasicBlock(
          (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu1): ReLU(inplace=True)
          (conv1): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu2): ReLU(inplace=True)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (dp): Dropout2d(p=0.5, inplace=False)
        )
      )
    )
  )
  (output_conv): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1))
)
</pre>
</div>
</div>
</div>
</div>
</div>

</div>
</div>

 


    </main>
    